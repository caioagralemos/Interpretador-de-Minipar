SEQ {
# Entradas e inicialização
input_val = 1;
output_desire = 0;
input_weight = 0.5;
learning_rate = 0.01;
bias = 1;
bias_weight = 0.5;
error = 1000;
iteration = 0;

output("Entrada: ");
output(input_val);
output("Desejado: ");
output(output_desire);

# Função de ativação
function activation(x) {
    if (x >= 0) {
        output(1);
        return 1;
    } else {
        output(0);
        return 0;
    }
}

# Laço de treinamento até erro zerar
while (error != 0) {
    iteration = iteration + 1;
    output("#### Iteração: ");
    output(iteration);
    output("Peso: ");
    output(input_weight);

    sum_val = input_val * input_weight + bias * bias_weight;

    output_val = activation(sum_val);

    output("Saída: ");
    output(output_val);

    error = output_desire - output_val;
    output("Erro: ");
    output(error);

    if (error != 0) {
        input_weight = input_weight + learning_rate * input_val * error;
        bias_weight = bias_weight + learning_rate * bias * error;
        output("Peso do bias: ");
        output(bias_weight);
    }
}

output("Parabéns!!! A Rede de um Neurônio Aprendeu");
output("Valor desejado: ");
output(output_desire);
}
